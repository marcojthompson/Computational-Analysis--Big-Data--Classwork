{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8: MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "Today you will be doing a few exercises that bend your mind to fit the MapReduce paradigm. It can be easy enough to accept the logic of how a `mapper` and a `reducer` produces a certain outcome, but to write them to produce a desired outcome requires a bit of mental gymnastics.\n",
    "\n",
    "The exercises today are simple.\n",
    "* First you will learn to run a MapReduce script in your terminal (since it doesn't work in Jupyter notebooks).\n",
    "* Then you will take a crash course in Python *generators*.\n",
    "* Finally you are going to write some MapReduce code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Running your first MapReduce job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, let's make sure you're all setup with `mrjob`: install it with `conda`, otherwise try `pip` so you can write MapReduce jobs in Python. After you've installed it, run the following MapReduce job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 8.1.1**: Follow the example on the last slide of today's lecture and run your very first MapReduce job! You should get the same output as what is shown on the slide. As your answer, insert all of the terminal output in a markdown cell below, indented by one tab (mark all of the text, hit tab so it turns orange, and hit enter).\n",
    ">*Hints:*\n",
    "\n",
    ">1. Create a `.py` file with the content:\n",
    "            \n",
    ">        from mrjob.job import MRJob\n",
    "> \n",
    ">        class MRWordCounter(MRJob):  \n",
    ">\n",
    ">            def mapper(self, _, line):\n",
    ">                for word in line.split():\n",
    ">                    yield word, 1\n",
    ">\n",
    ">            def reducer(self, key, values):\n",
    ">                yield key, sum(values)\n",
    ">\n",
    ">        if __name__ == '__main__':\n",
    ">            MRWordCounter.run()\n",
    "\n",
    ">2. Create a `.txt` file with the content:\n",
    ">        i am a twitter bot\n",
    ">        i am also a twitter bot\n",
    ">        wow such bot tweet also\n",
    ">        very bot like tweet also\n",
    "\n",
    ">3. Run the `.py` script with the `.txt` file as its argument in your terminal/console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crash course: *Generators*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here follows a small, non-exhaustive, technical crash course in Python generators. By now you may have noticed that the \"functions\" inside the `mrjob` class have `yield` statements rather than the good old `return` statements that you are familiar with. What does this mean?\n",
    "\n",
    "Python functions with `yield` statements are in fact not regular functions, they are *generators*. In brief, generators are a special type of function that *yield* output everytime the interpreter reaches a `yield` statement, and then, remembering where it left off, continues from that point the next time the generator instance is called to give output.\n",
    "\n",
    "#### How generators work\n",
    "Let's define a generator called `my_generator()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T13:10:14.025136Z",
     "start_time": "2019-11-05T13:10:14.021395Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def my_generator():\n",
    "    yield \"first call\"\n",
    "    yield \"second call\"\n",
    "    yield \"final call\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make an instance of this generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T13:10:14.576312Z",
     "start_time": "2019-11-05T13:10:14.573340Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "gen = my_generator()\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `next` function, we are then going to ask our new iterator object to give us some output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T13:10:15.111442Z",
     "start_time": "2019-11-05T13:10:15.107821Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this prints the output of the first `yield` statement that we put inside the generator. Let's run the same code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T13:10:26.176618Z",
     "start_time": "2019-11-05T13:10:26.172709Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AHA! Evidently, when calling it again, the interpreter continued from right after the first `yield`, and went straight to the next. So if we use `next` on it again it's going to give us the last string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T13:10:33.016691Z",
     "start_time": "2019-11-05T13:10:33.011858Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(next(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! Try to use `next` on it again and think about why it fails. You can also play around with other generators, for example try putting a `yield` statement inside a `for` loop and think about the output you get.\n",
    ">What you should realize, is that an iterator (recall: an instance of a generator) is like a tape that plays a series of `yield`s before it is over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generators in `mrjob`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the `mapper` and `reducer` are generators. Let's analyze the `mapper` generator from Ex. 8.1.1.\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        for word in line.split():\n",
    "            yield word, 1\n",
    "A *line* of text runs though it, gets split into words and `yield`ed into tuples that contain each word and a one. Let's say the line is \"i am a string a short string\" and code up an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-25T08:32:20.061716Z",
     "start_time": "2017-10-25T08:32:20.055526Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i', 1)\n",
      "('am', 1)\n",
      "('a', 1)\n",
      "('string', 1)\n",
      "('a', 1)\n",
      "('short', 1)\n",
      "('string', 1)\n"
     ]
    }
   ],
   "source": [
    "def mapper(line):\n",
    "    for word in line.split():\n",
    "        yield word, 1\n",
    "\n",
    "for output in mapper(\"i am a string a short string\"):\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I removed the `self` and `_` arguments from the generator, just so that it works outside of a `class`, but what happens inside hasn't changed. Really, REALLY try to make sense of this code, because it is key to understanding how MapReduce works in Python!\n",
    ">You should understand that when you put some data into the `mapper`, out of it comes a *sequence* of key-value pairs.\n",
    "\n",
    "Although the arguments to the `reducer` look slightly different, it works exactly the same. It operates on one key-values pair (note that *values* is plural now) at a time, where the key is whatever you defined it to be in the `mapper` and the values are itself an iterator over all the different values that were paired with the key in the implicitly handled *group-by-key* step. The `reducer` can even have multiple `yield` statements, one for each operation that you want to make on the values. It's also possible to have multi-step MapReduce operations â€“ one MapReduce operation followed by another MapReduce and so on.  You will see this in action in the exercises below.\n",
    "\n",
    ">Before moving on, I encourage you to play around with the script from Ex. 8.1.1, by insert some print statements here and there, deliberately breaking it, changing the output(s) of the `mapper` and the `reducer`, and so on. \n",
    "\n",
    "*Nerdy sidenote*: You could argue that the developers of `mrjob` might aswell have written their API so that the `mapper` and `reducer` were standard functions that returned a list of key-value pairs, rather than generators that produce them in sequence. The reason they chose generators is that they are much faster and have a smaller memory footprint.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Writing Your Own MapReduce Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright... Time for action. In this part of today's exercises you are going to apply your freshly acquired understanding of MapReduce to do some cool highly scalable computations. All the code you write here works as well on your computer as it does on a massively parallelized Hadoop data storage system, so while you may not experience serious speedups locally, you would if the code was deployed on e.g. some of Google's data storage clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 8.2.1**: Modify the script from Ex. 8.1.1 so that it instead of counting only the words in the input file, it counts the number of characters, words and lines in the file. Post your answer in two separate cells:(1) the code in the script in a code cell, and (2) the terminal output in a markdown cell with the text indented by one tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to 8.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to 8.2.1 cont."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 8.2.2**: Implement the \"Common friends\" example from today's lecture. Here is your data, you should put that into a text file:\n",
    "\n",
    ">        A B C D\n",
    ">        B A C D E\n",
    ">        C A B D E\n",
    ">        D A B C E\n",
    ">        E B C D\n",
    "    \n",
    ">I removed all but the letters, but you already know that the first letter in each line is a person and the following are their friends. Report your answer in the same fashion as above (code in one cell, terminal output in another)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to 8.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 8.2.3**: Lets go a bit deeper. In this exercise you will implement a MapReduce-MapReduce operation to do the same thing as above (compute the list of common friends), but takes as input friend-network data in a slightly more common format: \n",
    "\n",
    ">        A B\n",
    ">        A C\n",
    ">        A D\n",
    ">        B C\n",
    ">        B D\n",
    ">        B E\n",
    ">        C D\n",
    ">        C E\n",
    ">        D E\n",
    "\n",
    ">Each line is a \"friend-link\". The links are undirected and each only occurs once (\"A B\" implies \"B A\" but the latter won't appear in the data set).\n",
    "\n",
    ">Your job now, is to produce the same output as you did in Ex. 8.2.2, using this input data. To get started, use the template below, which shows how to chain together multiple MapReduce steps. Fill out the template and show the output that you get from the terminal when you run it. Clarify whether it corresponds with the output from Ex. 8.2.2.\n",
    "\n",
    ">*Hint: Try to write the first MapReduce step such that it outputs key-value pairs that correspond to the input data format from Ex. 8.2.2. Then you can reuse your solution to Ex. 8.2.2 in your second MapReduce step.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Answer to 8.2.3\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class CommonFriends(MRJob):\n",
    "\n",
    "    def mapper1(self, _, line):\n",
    "        #\n",
    "\n",
    "    def reducer1(self, key, values):\n",
    "        #\n",
    "\n",
    "    def mapper2(self, key, values):\n",
    "        #\n",
    "\n",
    "    def reducer2(self, key, values):\n",
    "        #\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper=self.mapper1,\n",
    "                reducer=self.reducer1\n",
    "            ),\n",
    "            MRStep(\n",
    "                mapper=self.mapper2,\n",
    "                reducer=self.reducer2\n",
    "            )\n",
    "        ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    CommonFriends.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T14:01:10.834257Z",
     "start_time": "2017-08-23T14:01:10.826472Z"
    }
   },
   "source": [
    ">**Ex. 8.2.4**: We can go even further! Let's add a **third** MapReduce step to count the number of triangles in a network (i.e., groups of 3 people where each person is a friend of the other two). Again use this input data:\n",
    "\n",
    ">        A B\n",
    ">        A C\n",
    ">        A D\n",
    ">        B C\n",
    ">        B D\n",
    ">        B E\n",
    ">        C D\n",
    ">        C E\n",
    ">        D E\n",
    "\n",
    ">to validate that your implementation works. It should produce 7 triangles.\n",
    "\n",
    ">1. Now compute the number of triangles in [this file](http://snap.stanford.edu/data/facebook_combined.txt.gz) which contains 88234 friendship links in an anonymized facebook network. Don't print the whole output, just report the number of traingles you get.\n",
    "\n",
    ">*Hint: Counting triangles is equivalent to counting \"common friends\". One way to do that is to just count the collective number of common friends that exist in a network. Depending on your implementation you might want to correct your result by a factor 3, since it is likely that you end up counting each triangle three times (one for each point in it).*\n",
    "\n",
    ">*Nerdy sidenote: Why would anyone want to count triangles??? Well, in network science there is a lot of statistical measures that include the count of triangles in a network. For example, the [clustering coefficient](https://en.wikipedia.org/wiki/Clustering_coefficient), which reveals the proportion of small closed loops in a network, is computed as the number of realized triangles divided by the number of possible triangles.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to 8.2.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">2. Do the same instead using all 2766607 road segments in California as your input. Go to [this site](https://www.cise.ufl.edu/research/sparse/matrices/SNAP/roadNet-CA.html) and download the data in Matrix Market format (`.mtx`). Unzip the file and remove the first 50 lines from it, since that is just markup that we don't need. The file is pretty big so you can expect it to take some time (~4 minutes on my computer). Report the number you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer to 8.2.4.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
