{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "*Due: November 9th, 13:15 Copenhagen (CET) time.* Some general remarks for handing in exercises:\n",
    "- Each exercise comes with context and code from the exercise-set of which it is a part. It is up to you to recycle the right code. If this notebook can be executed from top to bottom on another computer (given the right libraries are installed and data stored) it makes it easier to give points for exercises that were only partially finished for whatever reason\n",
    "- Make sure to answer each sub-exercise\n",
    "- Commenting amply on your results makes it easier to understand that you were on the right track, even if the answer was wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 4.3.1**: Investigate how well your model generalizes. You may have noticed that the performance seemed a little too good to be true in Ex 4.2.1.\n",
    "1. Why did you get such a high accuracy in the previous exercise?\n",
    "2. Split your data into a test and training set of equal size. Train the model only on the training set and report its accuracy and F1 score (for minority class) on both the training and test sets.\n",
    "3. Comment on the difference you observe.\n",
    ">\n",
    "> *Hint: Watch out for unbalanced class proportions! You may want to randomly reorder the rows of your datapoints and target labels so your training and test sets have the same amount of heroes and villains.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex. 4.4.1**: Let's put our classifier to use!\n",
    "* Retrain your model on all of your data (still only heroes and villains).\n",
    "* Get a team alliance representation of the ambiguous characters\n",
    "* Use the model the estimate the probability that each character is a villain (let's call this *villainness*). You can use the `.predict_proba` method on the model to get probability estimates rather than class assignments. It produces an array with two columns, where the 1st column is the probability of class 1 (which is heroes).\n",
    "* **Visualize the \"heroness\" distribution for all ambiguous characters**. Comment on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 5\n",
    "You should have a dataframe called `data_teams` with characters as rows and alliances as columns (+ one column for faction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex. 5.1.2**: Split your data (`data_teams`) into two subsets. One where characters are affiliated with X-men and one where they are not.\n",
    "1. What is the entropy of target labels in each subset?\n",
    "2. What is the weighted average entropy of the split?\n",
    "3. Write a function that computes the weighted average entropy of a split, given the data and team (name or id) on which to split the data. Show that it gives you the same split entropy that you obtained in point 2.\n",
    "4. Plot the distribution of split entropy for all features. Comment on the result. My figure looks [like this](https://dhsvendsen.github.io/images/BD_5_1_2_4.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Ex. 5.2.2**: *Fit* a logistic regression! You can use the `scipy` module `scipy.optimize.curve_fit`\n",
    "to fit a model to some data (i.e. find the best parameter values `w`). Below I have implemented a function that generates some 2d data with labels.\n",
    "\n",
    "Make a *scatterplot* of the data where each datapoint is coloured according to the prediction of the logistic regression:\n",
    "1. Using some sub-optimal values of w0, w1, w2\n",
    "2. Using your optimal (fitted) values of w0, w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 6.1.3**: Another very famous type of synthetic network is the Barabási–Albert (BA) network.\n",
    "1. Describe what a BA network is and how to create one.\n",
    "2. On the [`NetworkX` documentations site](https://networkx.github.io/documentation/networkx-2.2/reference/generators.html), find a method you can use for generating a BA network. Create one with $N=100$ nodes and number of new edges from each new node $m=2$.\n",
    "3. Plot the network\n",
    "4. Visualize the [degree distribution](https://en.wikipedia.org/wiki/Degree_distribution) of your newly created BA graph.\n",
    "5. Explain the main difference(s) you observe, when comparing to the ER network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex: 6.2.2**: Create a `networkx.Graph` that represents each partnership between characters, as an edge. Print the number of nodes, edges and average degree of the resulting network.\n",
    "**Do not** add characters that have no partners. And **do not** add links to partners of characters that are not in\n",
    "your dataset.\n",
    ">\n",
    "> *Hint 1: You don't have to explicitly add nodes. Adding an edge will automatically add the corresponding nodes*<br>\n",
    "> *Hint 2: As you know, many of the characters have a parenthesis in their name that is not important (like \"Loki\n",
    "(comics)\"). If you remove this parenthesis your plots in the following will look much nicer. E.g. the regex code\n",
    "`re.sub(\" \\(.+?\\)\", \"\", char)` will do the job of cleaning up a name like \"Loki (comics)\" for you. But then there's characters like \"Captain America (William Burnside)\"\n",
    "where you might want to keep the parenthesis. It's not a hard requirement that you handle this in an elegant way,\n",
    "just a suggestion for improving your analysis. In any event, ARGUE for what you do, even if that's doing nothing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex: 6.2.3**: Plot the degree distribution of your character network. What type of random network (synthetic network) does it resemble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
